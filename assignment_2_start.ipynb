{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# Import necessary packages here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# Helper function used to load datasets.\n",
    "def load_dataset(filename):\n",
    "  return pd.read_csv(filename)\n",
    "\n",
    "# Change the string to match your course number and name.\n",
    "output_str = \"5361AlvarezAlbert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: kNN Exercises\n",
    "\n",
    "#### Formula to Normalize data.\n",
    "![Normalize Formula](normalize.png \"Normalize Formula\")\n",
    "\n",
    "#### Formula to Standardize data.\n",
    "![Standardize Formula](standardize.png \"Standardize Formula\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# Getting started with KNN.\n",
    "#     1. Load data\n",
    "#     2. Split data in training and test sets using SKLearn\n",
    "#     3. Normalize/Standardize features as needed.\n",
    "X = load_dataset('movie_data.csv')\n",
    "Y = load_dataset('movie_labels.csv')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# This function should normalize a feature (column) of a dataset.\n",
    "def normalize_feature(data, feature):\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  return None\n",
    "\n",
    "# This function should standardize a feature (column) of a dataset.\n",
    "def standardize_feature(data, feature):\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# REQUIRED\n",
    "# Define the kNN algorithm.\n",
    "\n",
    "# This function should calculated the Euclidian distance between two datapoints.\n",
    "def euclidian_distance(dp1, dp2):\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  return None\n",
    "\n",
    "# This function should get the k nearest neighbors for a new datapoint.\n",
    "def get_neighbors(x_train, new_dp, k):\n",
    "  distances = []\n",
    "  neighbors = []\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  return neighbors\n",
    "  \n",
    "# This function should determine the class label for the current datapoint\n",
    "# based on the majority of class labels of its k neighbors.\n",
    "def predict_dp(neighbors, y_train):\n",
    "  predictions = None\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  return predictions\n",
    "\n",
    "# Use the kNN algorithm to predict the class labels of the test set\n",
    "# with k = 3\n",
    "k = 3\n",
    "predictions = []\n",
    "for datapoint in x_test:\n",
    "  \n",
    "  # Write your code here!\n",
    "  \n",
    "  continue\n",
    "\n",
    "# Calculate and print out the accuracy of your predictions!\n",
    "correct = sum([y_true == y_pred for y_true, y_pred in zip(y_test, predictions)])\n",
    "accuracy = (correct / len(y_test)) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# Load the datasets\n",
    "x_train = load_dataset('x_train_q3.csv')\n",
    "y_train = load_dataset('y_train_q3.csv')\n",
    "x_test = load_dataset('x_test_q3.csv')\n",
    "\n",
    "# Use the equation: y = w_0 + w_1x_1 + w_2x_2 + .... + w_nx_n\n",
    "# Calculate the \"Admission Rate\" given: w0=w1=w2=....=wn=1\n",
    "# Calcuate the Mean Square Error for training data.\n",
    "def linear_regression_equation():\n",
    "    mse = 0\n",
    "    \n",
    "    # Write your code here!\n",
    "    \n",
    "    print(\"MSE using library: \", mse) \n",
    "    \n",
    "# Implement linear regression using SKLearn.    \n",
    "def linear_regression_library():\n",
    "    # write your code here\n",
    "\n",
    "    # Predict the output for the test dataset\n",
    "    y_pred = None # write your code here!\n",
    "    \n",
    "    y_pred_df = pd.DataFrame(y_pred, columns=['Admission Rate']).to_csv(f\"{output_str}_pq3.csv\", index=False)\n",
    "    \n",
    "linear_regression_equation()\n",
    "linear_regression_library()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "# Load dataset, process, and prepare for perceptron.\n",
    "df = load_dataset('movie_reviews.csv')\n",
    "\n",
    "# Processing code removed.\n",
    "# The long reviews are cleaned and converted into a feature set.\n",
    "\n",
    "# Load data that is already processed and remove unneccesary column.\n",
    "df = load_dataset('movie_reviews_clean.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# We should change the value of sentiment to be 1 for positive\n",
    "# and -1 for negative.\n",
    "\n",
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "\n",
    "# Set X and Y.\n",
    "Y = df[\"sentiment\"]\n",
    "X = df.iloc[:, 0:200]\n",
    "\n",
    "# Function that implements the baseline perceptron algorithm.\n",
    "def baseline_perceptron(X,Y):\n",
    "  max_iter = 100000\n",
    "  w = np.zeros(X.shape[1])\n",
    "  b = 0\n",
    "  i = 0\n",
    "  correct_count = 0\n",
    "  while correct_count < X.shape[0] and i < max_iter:\n",
    "    # exit when number of mistakes = 0\n",
    "    # if mistake > 0 iterate over entire perceptron\n",
    "    i = i+1\n",
    "    for j in range(X.shape[0]):\n",
    "      #implement baseline perceptron\n",
    "      #iterate over your entire dataset\n",
    "      continue\n",
    "  #return i epoch at which you exit or epoch at which your algorithm converges\n",
    "  return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
